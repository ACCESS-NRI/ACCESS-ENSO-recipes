{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e444b8f-e137-4087-8abd-48ef10a4adfb",
   "metadata": {},
   "source": [
    "# ENSO_pattern: zonal structure of boreal winter SST anomalies in the equatorial Pacific\n",
    "\n",
    "Computes the zonal root mean square error (RMSE) of boreal winter (December) sea surface temperature anomalies (SSTA) along the equatorial Pacific (150°E–90°W), averaged meridionally over 5°S–5°N. Observations and model outputs are compared after processing, including smoothing with a 5-month triangular-weighted moving average.\n",
    "\n",
    "## Datasets Used for SSTA Comparison\n",
    "The following reference datasets are employed to evaluate the ENSO-related SST patterns in model simulations:\n",
    "\n",
    "- **TropFlux** (1979–2018): The primary dataset for comparison, providing high-quality estimates of surface fluxes and anomalies designed for tropical ocean and climate studies, combining in-situ measurements with satellite-derived data.\n",
    "Additional datasets include:\n",
    "\n",
    "- **20CRv2** (1871–2012): A century-scale reanalysis leveraging surface pressure observations to reconstruct global atmospheric conditions.- **ERA-Interim** (1979–2018): A widely used reanalysis dataset offering high-resolution estimates of atmospheric and surface variables with robust data assimilation techniques.\n",
    "- **ERSSTv5** (1854–2018): A globally gridded dataset of historical SSTs derived from in-situ measurements and optimised for climate monitoring and ENSO studies.\n",
    "- **HadISST** (1870–2018): A long-term SST and sea ice dataset combining ship and buoy observations with historical data reconstruction.\n",
    "- **NCEP2** (1979–2018): The second-generation reanalysis dataset from NCEP, improving upon the earlier version for global atmospheric and oceanic variability analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a2571a-c2f1-4ac8-a272-d4c731c062cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esmvalcore.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a20485d9-9e93-4564-9fc0-f07c64a3bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_datasets = {\n",
    "\"ACCESS-ESM1-5\": \n",
    "    Dataset(\n",
    "    short_name='tos',\n",
    "    project='CMIP6',\n",
    "    mip=\"Omon\",\n",
    "    exp=\"historical\",\n",
    "    ensemble=\"r1i1p1f1\",\n",
    "    timerange=\"19790101/20190101\",\n",
    "    dataset=\"ACCESS-ESM1-5\",\n",
    "    grid=\"gn\"\n",
    ")}\n",
    "\n",
    "model_datasets[\"ACCESS-ESM1-5\"].add_supplementary(short_name='areacello', mip='Ofx')\n",
    "\n",
    "obs_datasets = {\n",
    "\"HadISST\": \n",
    "    Dataset(\n",
    "    short_name='tos',\n",
    "    dataset='HadISST',\n",
    "    mip=\"Omon\",\n",
    "    project='OBS',\n",
    "    type='reanaly',\n",
    "    tier=2),\n",
    "\"ERSSTv5\":\n",
    "    Dataset(\n",
    "    short_name='tos',\n",
    "    dataset='NOAA-ERSSTv5',\n",
    "    mip=\"Omon\",\n",
    "    project='OBS6',\n",
    "    type='reanaly',\n",
    "    tier=2),\n",
    "# \"ERA-Interim\":  #kj13\n",
    "#     Dataset(\n",
    "#     short_name='tos',\n",
    "#     dataset='ERA-Interim',\n",
    "#     mip=\"Omon\",\n",
    "#     project='OBS6',\n",
    "#     type='reanaly',\n",
    "#     timerange=\"19790101/20190101\",\n",
    "#     tier=3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e048061-f220-4e34-820a-629c7b6b5580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:esmvalcore.local:Configured 'OBS6' rootpaths '/scratch/nf33/public/datasets' do not exist\n"
     ]
    }
   ],
   "source": [
    "model_datasets = {name: dataset.load() for name, dataset in model_datasets.items()}\n",
    "obs_datasets = {name: dataset.load() for name, dataset in obs_datasets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4b8d63-b98d-4195-a6cb-7a5316c6db3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esmvalcore.preprocessor import anomalies\n",
    "from esmvalcore.preprocessor import area_statistics\n",
    "# from esmvalcore.preprocessor import climate_statistics\n",
    "from esmvalcore.preprocessor import rolling_window_statistics\n",
    "from esmvalcore.preprocessor import convert_units\n",
    "from esmvalcore.preprocessor import extract_region\n",
    "from esmvalcore.preprocessor import extract_month\n",
    "from esmvalcore.preprocessor import regrid\n",
    "from esmvalcore.preprocessor import detrend\n",
    "from esmvalcore.preprocessor import meridional_statistics\n",
    "from esmvalcore.preprocessor import mask_landsea\n",
    "import iris\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import iris.quickplot as qplt\n",
    "import numpy as np\n",
    "import scipy.stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61674b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pattern enso, eq\n",
    "def sst_enso(cube):\n",
    "    nino34_latext_region = {\"start_longitude\": 190., \"end_longitude\": 240., \"start_latitude\": -5., \"end_latitude\": 5.}\n",
    "    cube = convert_units(cube, units=\"degC\")\n",
    "    # cube = mask_landsea(cube, mask_out=\"land\") #shp or land fraction\n",
    "# detrend?\n",
    "    cube = extract_region(cube, **nino34_latext_region)\n",
    "    cube = rolling_window_statistics(cube, coordinate='time', operator='mean', window_length=5)\n",
    "    cube = rolling_window_statistics(cube, coordinate='time', operator='mean', window_length=5)\n",
    "    cube = area_statistics(cube,operator='mean')\n",
    "    cube = extract_month(cube,12) # get DEC\n",
    "    #remove time mean\n",
    "    cube = anomalies(cube,period='monthly')\n",
    "    \n",
    "    return cube\n",
    "\n",
    "def sst_eq(cube):\n",
    "    region = {\"start_longitude\": 150., \"end_longitude\": 270., \"start_latitude\": -5., \"end_latitude\": 5.}\n",
    "    cube = regrid(cube, target_grid=\"1x1\", scheme=\"linear\")\n",
    "    cube = convert_units(cube, units=\"degC\")\n",
    "    # cube = mask_landsea(cube, mask_out=\"land\")\n",
    "    cube = extract_region(cube, **region)\n",
    "    cube = rolling_window_statistics(cube, coordinate='time', operator='mean', window_length=5)\n",
    "    cube = rolling_window_statistics(cube, coordinate='time', operator='mean', window_length=5)\n",
    "    cube = extract_month(cube,12) # get DEC\n",
    "# remove time mean\n",
    "    cube = anomalies(cube, period='monthly')\n",
    "    cube = meridional_statistics(cube, 'mean')\n",
    "\n",
    "    return cube\n",
    "\n",
    "#linear regression of sst_enso on sst_eq\n",
    "def lin_regress(cube_ssta, cube_nino34): #1d \n",
    "    slope_ls = []\n",
    "    for lon_slice in cube_ssta.slices(['time']): # iterate over 120 lon points\n",
    "        res = scipy.stats.linregress(cube_nino34.data, lon_slice.data)\n",
    "        # res = scipy.stats.linregress(lon_slice.data, cube_nino34.data)\n",
    "        slope_ls.append(res[0])\n",
    "\n",
    "    return cube_ssta.coord('longitude').points, slope_ls\n",
    "\n",
    "# rmse = np.sqrt(np.mean((obs_regressed - model_regressed) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d57ecdb-e423-49e6-ab56-5b4c626c9634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sst_eq2(cube):\n",
    "    region = {\"start_longitude\": 150., \"end_longitude\": 270., \"start_latitude\": -15., \"end_latitude\": 15.}\n",
    "    cube = regrid(cube, target_grid=\"1x1\", scheme=\"linear\")\n",
    "    cube = convert_units(cube, units=\"degC\")\n",
    "\n",
    "    cube = extract_region(cube, **region)\n",
    "    cube = rolling_window_statistics(cube, coordinate='time', operator='mean', window_length=5)\n",
    "    cube = rolling_window_statistics(cube, coordinate='time', operator='mean', window_length=5)\n",
    "    cube = extract_month(cube,12) # get DEC\n",
    "\n",
    "    cube = anomalies(cube, period='monthly')\n",
    "    return cube\n",
    "    \n",
    "# iterate over lat/lon for 2d\n",
    "def lin_regress_2(cube_ssta, cube_nino34): # cube_ssta(no meridional_statistics)\n",
    "    slope_ls = []\n",
    "    ## flatten and reshape\n",
    "    for lonlat_slice in cube_ssta.slices(['time']):\n",
    "        res = scipy.stats.linregress(cube_nino34.data, lonlat_slice.data)\n",
    "        slope_ls.append(res[0])\n",
    "    \n",
    "    slope_array = np.array(slope_ls)\n",
    "    ssta_reg = slope_array.reshape(cube_ssta.shape[1],cube_ssta.shape[2])\n",
    "    cube = iris.cube.Cube(ssta_reg, long_name='regression ENSO SSTA',\n",
    "                          dim_coords_and_dims=[(cube_ssta.coord('latitude'),0),\n",
    "                                               (cube_ssta.coord('longitude'),1)])\n",
    "\n",
    "    return cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "821d528c-da59-4b25-9bfa-3d7a53a61a9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4881: IrisIgnoringBoundsWarning: The bounds of coordinate 'time' were ignored in the rolling window operation.\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4881: IrisIgnoringBoundsWarning: The bounds of coordinate 'time' were ignored in the rolling window operation.\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4881: IrisIgnoringBoundsWarning: The bounds of coordinate 'time' were ignored in the rolling window operation.\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4881: IrisIgnoringBoundsWarning: The bounds of coordinate 'time' were ignored in the rolling window operation.\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4330: IrisUserWarning: Collapsing spatial coordinate 'latitude' without weighting\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4881: IrisIgnoringBoundsWarning: The bounds of coordinate 'time' were ignored in the rolling window operation.\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4881: IrisIgnoringBoundsWarning: The bounds of coordinate 'time' were ignored in the rolling window operation.\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4881: IrisIgnoringBoundsWarning: The bounds of coordinate 'time' were ignored in the rolling window operation.\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4881: IrisIgnoringBoundsWarning: The bounds of coordinate 'time' were ignored in the rolling window operation.\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4881: IrisIgnoringBoundsWarning: The bounds of coordinate 'time' were ignored in the rolling window operation.\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4881: IrisIgnoringBoundsWarning: The bounds of coordinate 'time' were ignored in the rolling window operation.\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4881: IrisIgnoringBoundsWarning: The bounds of coordinate 'time' were ignored in the rolling window operation.\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4881: IrisIgnoringBoundsWarning: The bounds of coordinate 'time' were ignored in the rolling window operation.\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4330: IrisUserWarning: Collapsing spatial coordinate 'latitude' without weighting\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4881: IrisIgnoringBoundsWarning: The bounds of coordinate 'time' were ignored in the rolling window operation.\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4881: IrisIgnoringBoundsWarning: The bounds of coordinate 'time' were ignored in the rolling window operation.\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4330: IrisUserWarning: Collapsing spatial coordinate 'latitude' without weighting\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4881: IrisIgnoringBoundsWarning: The bounds of coordinate 'time' were ignored in the rolling window operation.\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4881: IrisIgnoringBoundsWarning: The bounds of coordinate 'time' were ignored in the rolling window operation.\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4881: IrisIgnoringBoundsWarning: The bounds of coordinate 'time' were ignored in the rolling window operation.\n",
      "  warnings.warn(\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.05/lib/python3.11/site-packages/iris/cube.py:4881: IrisIgnoringBoundsWarning: The bounds of coordinate 'time' were ignored in the rolling window operation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_datasets_prep1 = {name: sst_enso(dataset) for name, dataset in model_datasets.items()}\n",
    "model_datasets_prep2 = {name: sst_eq(dataset) for name, dataset in model_datasets.items()}\n",
    "model_datasets_prep3 = {name: sst_eq2(dataset) for name, dataset in model_datasets.items()}\n",
    "\n",
    "obs_datasets_prep1 = {name: sst_enso(dataset) for name, dataset in obs_datasets.items()}\n",
    "obs_datasets_prep2 = {name: sst_eq(dataset) for name, dataset in obs_datasets.items()}\n",
    "obs_datasets_prep3 = {name: sst_eq2(dataset) for name, dataset in obs_datasets.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1fc647-03a5-472e-8264-41ded88a5a63",
   "metadata": {},
   "source": [
    "# Diagnostic Level 1\n",
    "\n",
    "The first level shows the diagnostic used to compute the metric and highlight the main differences between the model and the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0607dbd0-4565-4fe9-8db3-75f3602f027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## linear regression sst_eq on sst_enso\n",
    "\n",
    "def format_longitude(x, pos):\n",
    "    if x > 180:\n",
    "        return f'{int(360 - x)}°W'\n",
    "    elif x == 180:\n",
    "        return f'{int(x)}°'\n",
    "    else:\n",
    "        return f'{int(x)}°E'\n",
    "\n",
    "\n",
    "reg_mod = lin_regress(model_datasets_prep2[\"ACCESS-ESM1-5\"], model_datasets_prep1[\"ACCESS-ESM1-5\"])\n",
    "\n",
    "# return slope data to longitude - array?\n",
    "plt.plot(reg_mod[0], reg_mod[1], label=\"ACCESS-ESM1-5\") #units\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(format_longitude))\n",
    "\n",
    "reg = lin_regress(obs_datasets_prep2[\"HadISST\"], obs_datasets_prep1[\"HadISST\"])\n",
    "plt.plot(reg[0],reg[1], color='black',label='ref: HadISST')\n",
    "\n",
    "plt.yticks(np.arange(-2,3, step=1))\n",
    "plt.axhline(y=0, color='black', linewidth=1)\n",
    "plt.ylabel(\"reg(ENSO SSTA, SSTA)\")\n",
    "plt.title('ENSO pattern') #\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--')\n",
    "\n",
    "rmse = np.sqrt(np.mean((np.array(reg[1]) - np.array(reg_mod[1])) ** 2)) #metric\n",
    "\n",
    "plt.text(0.5, 0.95, f\"RMSE: {rmse:.2f} \", fontsize=12, ha='center', transform=plt.gca().transAxes,\n",
    "        bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17d2857-6513-47d1-8aad-12c4576b0145",
   "metadata": {},
   "source": [
    "**Figure 1**: Zonal structure of sea surface temperature anomalies (SSTA) in the equatorial Pacific (averaged between 5°S and 5°N). The figure highlights the zonal distribution of SSTA associated with ENSO, which is typically overestimated west of the dateline; in this case, the anomalies are too strong in the central Pacific. The black curve represents the reference data, while the blue curve corresponds to the model output. The derived metric is the zonal root mean square error (RMSE) between the model and reference curves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb3c318-5251-4c61-a74e-b06c39a6765a",
   "metadata": {},
   "source": [
    "## Diagnostic Level 2\n",
    "\n",
    "The second level shows the broader picture to better understand the spatial pattern of ENSO: the map of the anomalies in the equatorial Pacific.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ba960-7aac-42cc-98ba-104a5bf12d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2_mod = lin_regress_2(model_datasets_prep3[\"ACCESS-ESM1-5\"], model_datasets_prep1[\"ACCESS-ESM1-5\"])\n",
    "reg2_obs = lin_regress_2(obs_datasets_prep3[\"HadISST\"], obs_datasets_prep1[\"HadISST\"])\n",
    "#make dict process\n",
    "process = {\"ACCESS-ESM1-5\":reg2_mod , \"HadISST\":reg2_obs} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b5f520-9f7f-4c00-85ec-e8d4881dc758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import iris.plot as iplt\n",
    "import matplotlib.colors as mcolors\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "fig = plt.figure(figsize=(20, 7))\n",
    "proj = ccrs.Orthographic(central_longitude=210.0)\n",
    "i =121\n",
    "# process = {**model_datasets_prep3, **obs_datasets_prep3}\n",
    "\n",
    "\n",
    "for label, cube in process.items():\n",
    "    \n",
    "    ax1 = plt.subplot(i,projection=proj)\n",
    "    ax1.add_feature(cfeature.LAND, facecolor='gray')  # Add land feature with gray color\n",
    "    ax1.coastlines()\n",
    "    cf1 = iplt.contourf(cube, levels=np.arange(-1.5,2,0.1), cmap='RdBu_r')\n",
    "    # cf1 = plt.contourf(reg2[0],reg2[1],reg2[2], cmap='RdBu_r', levels=np.arange(0,2,0.1))\n",
    "\n",
    "    ax1.set_extent([130, 290, -20, 20], crs=ccrs.PlateCarree())\n",
    "    ax1.set_title(label)\n",
    "\n",
    "    # Add gridlines for latitude and longitude\n",
    "    gl1 = ax1.gridlines(draw_labels=True, linestyle='--')\n",
    "    gl1.top_labels = False\n",
    "    gl1.right_labels = False\n",
    "\n",
    "    i+=1\n",
    "\n",
    "\n",
    "# Add a single colorbar at the bottom\n",
    "cax = plt.axes([0.15,0.08,0.7,0.05])\n",
    "cbar = fig.colorbar(cf1, cax=cax, orientation='horizontal', extend='both', ticks=np.arange(-2,2.5,0.5))\n",
    "cbar.set_label('regression(ENSO SSTA, SSTA) (°C/°C)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29abee3-7d96-4c78-9830-e9f1c9b63fb6",
   "metadata": {},
   "source": [
    "Figure 2: sea surface temperature anomalies (SSTA) associated with ENSO in the equatorial Pacific, showing usually the SSTA too far west (here too strong in the central Pacific). The left and right maps show respectively the reference and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3421df06-b1ec-4e78-80b2-328d34ef347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accessvis\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import xarray as xr\n",
    "import lavavu\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.colors as mcolors\n",
    "import cmocean\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf4ad8-6e37-4eb9-ae72-44fc0f19889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_data = reg2_obs\n",
    "model_data = reg2_mod\n",
    "\n",
    "def generate_rgba(data, cmap, vmin, vmax):\n",
    "    data = model_data.data  # 2D numpy array\n",
    "    lon = model_data.coord('longitude').points\n",
    "    lat = model_data.coord('latitude').points\n",
    "    \n",
    "    lon2d, lat2d = np.meshgrid(lon, lat)\n",
    "    \n",
    "    # cmap = cmocean.cm.balance\n",
    "    norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 3), dpi=100)\n",
    "    cf = ax.contourf(lon2d, lat2d, data, cmap=cmap, norm=norm, levels=20)\n",
    "    ax.axis('off')\n",
    "    fig.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    rgba = np.frombuffer(fig.canvas.tostring_argb(), dtype=np.uint8)\n",
    "    rgba = rgba.reshape(fig.canvas.get_width_height()[::-1] + (4,))  # (H, W, 4)\n",
    "\n",
    "    rgba = rgba[:, :, [1, 2, 3, 0]]\n",
    "    plt.close(fig)\n",
    "    return rgba\n",
    "\n",
    "def resize_rgba(data, width, height):\n",
    "    #If the original image is of type uint8, it needs to be converted to float32 before resizing.\n",
    "    rgba_float = rgba.astype(np.float32) / 255.0\n",
    "\n",
    "    # Resize the image (while preserving the number of channels).\n",
    "    rgba_resized = resize(rgba_float, (width, height, 4), preserve_range=True, anti_aliasing=True)\n",
    "    \n",
    "    # change back to uint8\n",
    "    rgba_resized = np.clip(rgba_resized * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "    return rgba_resized\n",
    "\n",
    "def pad_rgba(data, pad_width,pad_height,pad_depth=None,constant_values=255):\n",
    "    if pad_depth:\n",
    "        padded_rgba = np.pad(\n",
    "                    data,\n",
    "                    pad_width=(pad_width, pad_height, pad_depth),\n",
    "                    mode='constant',\n",
    "                    constant_values=constant_values\n",
    "        )\n",
    "    else:\n",
    "         padded_rgba = np.pad(\n",
    "                    data,\n",
    "                    pad_width=(pad_width, pad_height), \n",
    "                    mode='constant',\n",
    "                    constant_values=constant_values\n",
    "        )\n",
    "    return padded_rgba\n",
    "\n",
    "def normalise_array(values, minimum=None, maximum=None):\n",
    "    \"\"\"\n",
    "    Normalize an array to the range [0,1]\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    values : numpy.ndarray\n",
    "        Values to convert, numpy array\n",
    "    minimum: number\n",
    "        Use a fixed minimum bound, default is to use the data minimum\n",
    "    maximum: number\n",
    "        Use a fixed maximum bound, default is to use the data maximum\n",
    "    \"\"\"\n",
    "\n",
    "    # Ignore nan when getting min/max\n",
    "    if not minimum:\n",
    "        minimum = np.nanmin(values)\n",
    "    if not maximum:\n",
    "        maximum = np.nanmax(values)\n",
    "\n",
    "    # Normalise\n",
    "    array = (values - minimum) / (maximum - minimum)\n",
    "    # Clip out of [0,1] range - in case defined range is not the global minima/maxima\n",
    "    array = np.clip(array, 0, 1)\n",
    "\n",
    "    return array\n",
    "\n",
    "def opacity_rgba(padded_array, opacity_array):\n",
    "    array = normalise_array(opacity_array)\n",
    "    oarray = array\n",
    "    oarray = np.nan_to_num(oarray)\n",
    "    oarray = (oarray * 255).astype(np.uint8)\n",
    "    padded_array[::, ::, 3] = oarray\n",
    "    return padded_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d66e02-82b7-4f6a-8eb6-316f5e65603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('RdBu_r')\n",
    "\n",
    "rgba=generate_rgba(model_data.data, cmap = cmap, vmin=0, vmax=64)\n",
    "resized_rgba=resize_rgba(rgba,width=150,height=600)\n",
    "padded_rgba=pad_rgba(resized_rgba,pad_width=(375, 375),pad_height=(750, 450),pad_depth=(0, 0))\n",
    "opacity_array = resize(model_data.data, (150, 600), order=1, preserve_range=True, anti_aliasing=True)\n",
    "padded_opacity_array=pad_rgba(opacity_array,pad_width=(375, 375),pad_height=(750, 450),constant_values=0)\n",
    "opacitied_rgba=opacity_rgba(padded_rgba, padded_opacity_array)\n",
    "\n",
    "lv = accessvis.plot_earth(texture='bluemarble', background=\"white\", vertical_exaggeration=20)\n",
    "lv.rotation(15.0, -180.0, 0.0) #Rotate to Australia\n",
    "lv.set_properties(diffuse=0.8, ambient=0.1, specular=0.35, shininess=0.03, light=[1,1,0.98]) # make pretty\n",
    "lv.brightness_contrast_saturation(0.5, 0.5, 0.65)\n",
    "accessvis.update_earth_values(lv, dataMode=0, data=opacitied_rgba)\n",
    "\n",
    "lv.window(resolution=(700,700))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
